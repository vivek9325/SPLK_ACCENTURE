If- Else Statement -------------

index="vk_idx" sourcetype="csv" |dedup severity|table severity | eval state=if(severity<3,"High","Low") | sort severity


Case statement ----

index="vk_idx" sourcetype="csv" 
| dedup severity 
| table severity 
| eval state=case(severity=1,"Critical", severity=2, "High", severity=3, "Low",1=1, "info")
| sort severity

Chart ---

index="vk_idx" sourcetype="csv" 
|chart count by current_ticket_state, severity


timechart ----

index="vk_idx" sourcetype="csv" 
|timechart count by current_ticket_state


index="vk_idx" sourcetype="csv" 
| table _time, severity, time_submitted 
| eval time_submitted_epoc = strptime(time_submitted, "%d-%m-%y %H:%M") 
| eval _time = time_submitted_epoc 
| timechart span=1mon count by severity


Single Value Visualization -----

index="vk_idx" sourcetype="csv" 
|stats count


index="vk_idx" sourcetype="csv" 
|timechart count


Geo Map -----

index="vk_idx" sourcetype="csv" source="vendors.csv" 
| geostats latfield=VendorLatitude longfield=VendorLongitude count by Vendor

Addcoltotal ----

index="vk_idx" source="Sample_tickets.csv" 
| chart count by current_ticket_state, severity 
| addcoltotals label=total labelfield=current_ticket_state


Addtotals ----

index="vk_idx" source="Sample_tickets.csv" 
| chart count by current_ticket_state, severity 
| addcoltotals label=total labelfield=current_ticket_state 
| addtotals fieldname=sum


Rex ----------------

https://regex101.com/
 
https://www.debuggex.com/cheatsheet/regex/pcre

source="data.txt" index="vk_idx" sourcetype="vk_txt" | rex field=_raw "From:\s+<(?P<from_id>.*)>\s+To" | table from_id, _raw

source="data.txt" index="vk_idx" sourcetype="vk_txt" | rex field=_raw "From:\s+<(?P<from_id>.*)>\s+To:\s+<(?P<to_id>.*)>" | table from_id, to_id, _raw

| makeresults 
| eval text="Vk;search;savedsearch" 
| rex field=text "(?P<username>\w+);(?P<appname>\w+);(?P<savedsearch>\w+)"


| makeresults 
| eval credit_card_number = "1234-5678-9101-1213" 
| rex field=credit_card_number "(?P<digit>\d{4})" max_match=0



Lookup ----

See the data in lookup --
|inputlookup vk_sample_lookup.csv

Combine data from index and lookup file ----

index=vk_idx source="sample_tickets.csv" 
| table ticket_number,severity, current_ticket_state 
| lookup vk_sample_lookup.csv ticket_number OUTPUT time_taken as time_consumed

outputlookup command ----

append is true ----

| inputlookup vk_sample_lookup.csv 
| search ticket_number = "INC000020793173" 
| eval time_taken="100hrs" 
| outputlookup vk_sample_lookup.csv append=false

append is false

| inputlookup vk_sample_lookup.csv 
| search ticket_number = "INC000020793173" 
| eval time_taken="100hrs" 
| outputlookup vk_sample_lookup.csv append=true

KVStore Lookup ----


[ec2-user@ip-172-X-X-193 local]$ cat collections.conf
[vk_kvstore]
field.id = number
field.name = string
enforceType = false
accelerated_fields.myaccl = {"id" : 1}


Push Data in kvstore --


| makeresults 
| eval id = 1, name="Vivek" 
| fields - _time 
| outputlookup vk_kvstore1

Unique key in kvstore -----

|inputlookup vk_kvstore1 | eval key = _key



datamodel ---

|datamodel vk_dm vk_ssc search



transaction commands ----

source="tutorialdata.zip:*" host="ip-172-XX-XX-194.ap-south-1.compute.internal" index="vk_idx" | transaction JSESSIONID, clientip
 
source="tutorialdata.zip:*" host="ip-172-XX-XX-194.ap-south-1.compute.internal" index="vk_idx" 

| transaction JSESSIONID, clientip 

| highlight action
 
source="tutorialdata.zip:*" host="ip-172-XX-XX-194.ap-south-1.compute.internal" index="vk_idx" 

| transaction JSESSIONID, clientip maxevents=4 maxpause=2s maxspan=5s

| highlight action


Spath Commands -----

 
index="vk_idx" sourcetype="vk_xml" source="test_xml.txt" | spath path=purchases.book.author output=author
 
index="vk_idx" sourcetype="vk_xml" source="test_xml.txt" | spath path=purchases.book.title{@yearPublished} output=yearPublished
 
index="vk_idx" sourcetype="vk_xml" source="mixed_json_unstructured.json" 
| rex field=_raw "xyz-\s+(?P<json_field>.*)" 
| spath input=json_field path={}.timestamp output=time

Join ----

Inner Join ---

index=main source="sample_tickets.csv" 
|  table ticket_number, severity, current_ticket_state
| join type=inner ticket_number 
    [search index=vk_idx source=sample_lookup.csv 
    | table ticket_number, time_taken]


Left Join -----

index=main source="sample_tickets.csv" 
|  table ticket_number, severity, current_ticket_state
| join type=left ticket_number 
    [search index=vk_idx source=sample_lookup.csv ticket_number="INC000020793217"
    | table ticket_number, time_taken]


Append/Appendcols/Appendpipe ----

Append ---

index=main source="sample_tickets.csv" 
|  table ticket_number, severity, current_ticket_state
| appendc
    [search index=vk_idx source=sample_lookup.csv 
    |  table ticket_number, time_taken 
    |  rename ticket_number as incident_number, time_taken as time_consumed]

Appendcols ---

index=main source="sample_tickets.csv" 
|  table ticket_number, severity, current_ticket_state
| appendcols
    [search index=vk_idx source=sample_lookup.csv 
    |  table ticket_number, time_taken 
    |  rename ticket_number as incident_number, time_taken as time_consumed]

Appendpipe ---

index=main source="sample_tickets.csv" 
| stats count by severity, current_ticket_state 
| appendpipe 
    [| stats sum(count) as count by severity 
    | eval current_ticket_state = "Sum of Event Severity wise"]
| sort severity


Summary Index ----

index=main source="Sample_tickets.csv" 
| stats count by asset_id, current_ticket_state 
| collect index=vk_summary testmode=false

index=main source="Sample_tickets.csv" 
| stats count by asset_id, current_ticket_state 
| collect index=vk_summary testmode=true

index=main source="Sample_tickets.csv" 
| stats count by asset_id, current_ticket_state 
| collect index=vk_summary testmode=false marker="search_name=asset"


index=main source="Sample_tickets.csv" 
| stats count by asset_id, current_ticket_state 
| collect index=vk_summary testmode=true marker="search_name=asset"

Eventstats ----

index=main source="Sample_tickets.csv"
| eventstats count by severity


Stramstats ---

| makeresults count=3
| streamstats count

MultiKv ---

index="main" sourcetype="vk_multikv" 
|  multikv forceheader=2

index="main" sourcetype="vk_multikv" 
|  multikv noheader=t

Working with MV Command ---

index="main" sourcetype="csv" source="data.csv" 
|table "first name", "last name", occupation, salary 
| eval field1 = mvappend("first name", "last name", occupation, salary)

index="main" sourcetype="csv" source="data.csv" 
|table "first name", "last name", occupation, salary 
| eval field1 = mvappend("first name", "last name", occupation, salary)
| eval count_mv = mvcount(field1)
| eval count2 = mvcount("first name")


EventBreaking ----------

[ __auto__learned__ ]
SHOULD_LINEMERGE=true
LINE_BREAKER=([\r\n]*)<messages>
NO_BINARY_CHECK=true
MUST_BREAK_AFTER=</messages>
BREAK_ONLY_BEFORE=<messages>


